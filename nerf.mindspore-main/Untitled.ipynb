{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b2ba066-06e9-4ede-9f0e-04488a8d0f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: __main__.py [-h] [--config CONFIG] --name NAME [--base_dir BASE_DIR]\n",
      "                   [--data_dir DATA_DIR] [--cap_n_iters CAP_N_ITERS]\n",
      "                   [--net_depth NET_DEPTH] [--net_width NET_WIDTH]\n",
      "                   [--net_depth_fine NET_DEPTH_FINE]\n",
      "                   [--net_width_fine NET_WIDTH_FINE] [--cap_n_rand CAP_N_RAND]\n",
      "                   [--l_rate L_RATE] [--l_rate_decay L_RATE_DECAY]\n",
      "                   [--chunk CHUNK] [--net_chunk NET_CHUNK] [--no_batching]\n",
      "                   [--no_reload] [--gpu GPU] [--device {GPU,CPU,Ascend}]\n",
      "                   [--cap_n_samples CAP_N_SAMPLES]\n",
      "                   [--cap_n_importance CAP_N_IMPORTANCE] [--perturb PERTURB]\n",
      "                   [--use_view_dirs] [--i_embed I_EMBED]\n",
      "                   [--multi_res MULTI_RES] [--multi_res_views MULTI_RES_VIEWS]\n",
      "                   [--raw_noise_std RAW_NOISE_STD] [--render_only]\n",
      "                   [--render_test] [--render_factor RENDER_FACTOR]\n",
      "                   [--dataset_type DATASET_TYPE] [--test_skip TEST_SKIP]\n",
      "                   [--shape SHAPE] [--white_bkgd] [--half_res]\n",
      "                   [--factor FACTOR] [--no_ndc] [--lin_disp] [--spherify]\n",
      "                   [--llff_hold LLFF_HOLD] [--i_print I_PRINT] [--i_img I_IMG]\n",
      "                   [--i_ckpt I_CKPT] [--i_testset I_TESTSET] [--ckpt CKPT]\n",
      "                   [--mode {PYNATIVE_MODE,GRAPH_MODE}]\n",
      "__main__.py: error: the following arguments are required: --name\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2022 Huawei Technologies Co., Ltd\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\"\"\"Buile and train model.\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import mindspore as md\n",
    "import numpy as np\n",
    "from engine import RendererWithCriterion, test_net, train_net\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data.load_llff import load_llff_data\n",
    "from models import VolumeRenderer\n",
    "from utils.config import get_config\n",
    "from utils.engine_utils import context_setup, create_nerf\n",
    "from utils.ray import generate_rays\n",
    "from utils.results_handler import save_image, save_video\n",
    "from utils.sampler import sample_grid_2d\n",
    "\n",
    "\n",
    "def train_pipeline(config, out_dir):\n",
    "    \"\"\"Train nerf model: data preparation, model and optimizer preparation, and model training.\"\"\"\n",
    "    md.set_seed(1)\n",
    "\n",
    "    print(\">>> Loading dataset\")\n",
    "\n",
    "    if config.dataset_type == \"blender\":\n",
    "        images, poses, render_poses, hwf, i_split = load_blender_data(config.data_dir, config.half_res,\n",
    "                                                                      config.test_skip)\n",
    "        print(\"Loaded blender\", images.shape, render_poses.shape, hwf, config.data_dir)\n",
    "        i_train, i_val, i_test = i_split\n",
    "        near = 2.0\n",
    "        far = 6.0\n",
    "\n",
    "        if config.white_bkgd:\n",
    "            images = images[..., :3] * images[..., -1:] + (1.0 - images[..., -1:])\n",
    "        else:\n",
    "            images = images[..., :3]\n",
    "\n",
    "    elif config.dataset_type == \"llff\":\n",
    "        images, poses, bds, render_poses, i_test = load_llff_data(\n",
    "            config.data_dir,\n",
    "            config.factor,\n",
    "            recenter=True,\n",
    "            bd_factor=0.75,\n",
    "            spherify=config.spherify,\n",
    "        )\n",
    "        hwf = poses[0, :3, -1]\n",
    "        poses = poses[:, :3, :4]\n",
    "        print(\"Loaded llff\", images.shape, render_poses.shape, hwf, config.data_dir)\n",
    "        if not isinstance(i_test, list):\n",
    "            i_test = [i_test]\n",
    "\n",
    "        if config.llff_hold > 0:\n",
    "            print(\"Auto LLFF holdout,\", config.llff_hold)\n",
    "            i_test = np.arange(images.shape[0])[::config.llff_hold]\n",
    "\n",
    "        i_val = i_test\n",
    "        i_train = np.array([i for i in np.arange(int(images.shape[0])) if (i not in i_test and i not in i_val)])\n",
    "\n",
    "        print(\"DEFINING BOUNDS\")\n",
    "        config.no_ndc = True\n",
    "        if config.no_ndc:\n",
    "            near = float(np.min(bds)) * 0.9\n",
    "            far = float(np.max(bds)) * 1.0\n",
    "        else:\n",
    "            near = 0.0\n",
    "            far = 1.0\n",
    "        print(\"NEAR FAR\", near, far)\n",
    "\n",
    "    else:\n",
    "        print(\"Unknown dataset type\", config.dataset_type, \"exiting\")\n",
    "        return\n",
    "\n",
    "    if config.render_test:\n",
    "        render_poses = poses[i_test.tolist()]\n",
    "\n",
    "    print(f\"TRAIN views: {i_train}\\nTEST views: {i_test}\\nVAL views: {i_val}\")\n",
    "\n",
    "    # Cast intrinsics to right types\n",
    "    cap_h, cap_w, focal = hwf\n",
    "    cap_h, cap_w = int(cap_h), int(cap_w)\n",
    "\n",
    "    hwf = [cap_h, cap_w, focal]\n",
    "    # Setup logging and directory for results\n",
    "    print(\">>> Saving checkpoints and results in\", out_dir)\n",
    "    # Create output directory if not existing\n",
    "\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    # Record current configuration\n",
    "    with open(os.path.join(out_dir, \"configs.txt\"), \"w+\", encoding=\"utf-8\") as config_f:\n",
    "        attrs = vars(config)\n",
    "        for k in attrs:\n",
    "            config_f.write(f\"{k} = {attrs[k]}\\n\")\n",
    "\n",
    "    # Create network models, optimizer and renderer\n",
    "    print(\">>> Creating models\")\n",
    "\n",
    "    # Create nerf model\n",
    "    (\n",
    "        start_iter,\n",
    "        optimizer,\n",
    "        model_coarse,\n",
    "        model_fine,\n",
    "        embed_fn,\n",
    "        embed_dirs_fn,\n",
    "    ) = create_nerf(config, out_dir)\n",
    "    # Training steps\n",
    "    global_steps = start_iter\n",
    "    # Create volume renderer\n",
    "    renderer = VolumeRenderer(\n",
    "        config.chunk,\n",
    "        config.cap_n_samples,\n",
    "        config.cap_n_importance,\n",
    "        config.net_chunk,\n",
    "        config.white_bkgd,\n",
    "        model_coarse,\n",
    "        model_fine,\n",
    "        embed_fn,\n",
    "        embed_dirs_fn,\n",
    "        near,\n",
    "        far,\n",
    "    )\n",
    "\n",
    "    renderer_with_criterion = RendererWithCriterion(renderer)\n",
    "    optimizer = md.nn.Adam(\n",
    "        params=renderer.trainable_params(),\n",
    "        learning_rate=config.l_rate,\n",
    "        beta1=0.9,\n",
    "        beta2=0.999,\n",
    "    )\n",
    "\n",
    "    train_renderer = md.nn.TrainOneStepCell(renderer_with_criterion, optimizer)\n",
    "    train_renderer.set_train()\n",
    "\n",
    "    # Start training\n",
    "    print(\">>> Start training\")\n",
    "\n",
    "    cap_n_rand = config.cap_n_rand\n",
    "\n",
    "    # Move training data to GPU\n",
    "    images = md.Tensor(images)\n",
    "    poses = md.Tensor(poses)\n",
    "\n",
    "    # Maximum training iterations\n",
    "    cap_n_iters = config.cap_n_iters\n",
    "    if start_iter >= cap_n_iters:\n",
    "        return\n",
    "\n",
    "    train_model(config, out_dir, images, poses, i_train, i_test, cap_h, cap_w, focal, start_iter, optimizer,\n",
    "                global_steps, renderer, train_renderer, cap_n_rand, cap_n_iters)\n",
    "\n",
    "\n",
    "def train_model(config, out_dir, images, poses, i_train, i_test, cap_h, cap_w, focal, start_iter, optimizer,\n",
    "                global_steps, renderer, train_renderer, cap_n_rand, cap_n_iters):\n",
    "    \"\"\"Training model iteratively\"\"\"\n",
    "    with tqdm(range(1, cap_n_iters + 1)) as p_bar:\n",
    "        p_bar.n = start_iter\n",
    "\n",
    "        for _ in p_bar:\n",
    "            # Show progress\n",
    "            p_bar.set_description(f\"Iter {global_steps + 1:d}\")\n",
    "            p_bar.update()\n",
    "\n",
    "            # Start time of the current iteration\n",
    "            time_0 = time.time()\n",
    "\n",
    "            img_i = int(np.random.choice(i_train))\n",
    "\n",
    "            target = images[img_i]\n",
    "            pose = poses[img_i, :3, :4]\n",
    "\n",
    "            if cap_n_rand is not None:\n",
    "                rays_o, rays_d = generate_rays(cap_h, cap_w, focal,\n",
    "                                               md.Tensor(pose))  # (cap_h, cap_w, 3), (cap_h, cap_w, 3)\n",
    "                sampled_rows, sampled_cols = sample_grid_2d(cap_h, cap_w, cap_n_rand)\n",
    "                rays_o = rays_o[sampled_rows, sampled_cols]  # (cap_n_rand, 3)\n",
    "                rays_d = rays_d[sampled_rows, sampled_cols]  # (cap_n_rand, 3)\n",
    "\n",
    "                batch_rays = md.ops.Stack(axis=0)([rays_o, rays_d])\n",
    "                target_s = target[sampled_rows, sampled_cols]  # (cap_n_rand, 3)\n",
    "\n",
    "            loss, psnr = train_net(config, global_steps, train_renderer, optimizer, batch_rays, target_s)\n",
    "\n",
    "            p_bar.set_postfix(time=time.time() - time_0, loss=loss, psnr=psnr)\n",
    "\n",
    "            # Logging\n",
    "            # Save training states\n",
    "            if (global_steps + 1) % config.i_ckpt == 0:\n",
    "                path = os.path.join(out_dir, f\"{global_steps + 1:06d}.tar\")\n",
    "\n",
    "                md.save_checkpoint(\n",
    "                    save_obj=renderer,\n",
    "                    ckpt_file_name=path,\n",
    "                    append_dict={\"global_steps\": global_steps},\n",
    "                    async_save=True,\n",
    "                )\n",
    "                p_bar.write(f\"Saved checkpoints at {path}\")\n",
    "\n",
    "            # Save testing results\n",
    "            if (global_steps + 1) % config.i_testset == 0:\n",
    "                test_save_dir = os.path.join(out_dir, f\"test_{global_steps + 1:06d}\")\n",
    "                os.makedirs(test_save_dir, exist_ok=True)\n",
    "\n",
    "                p_bar.write(f\"Testing (iter={global_steps + 1}):\")\n",
    "\n",
    "                test_time, test_loss, test_psnr = test_net(\n",
    "                    cap_h,\n",
    "                    cap_w,\n",
    "                    focal,\n",
    "                    renderer,\n",
    "                    md.Tensor(poses[i_test.tolist()]),\n",
    "                    images[i_test.tolist()],\n",
    "                    on_progress=lambda j, img: save_image(j, img, test_save_dir),  # pylint: disable=cell-var-from-loop\n",
    "                    on_complete=lambda imgs: save_video(global_steps + 1, imgs, test_save_dir),  # pylint: disable=cell-var-from-loop\n",
    "                )\n",
    "\n",
    "                p_bar.write(\n",
    "                    f\"Testing results: [ Mean Time: {test_time:.4f}s, Loss: {test_loss:.4f}, PSNR: {test_psnr:.4f} ]\")\n",
    "\n",
    "            global_steps += 1\n",
    "\n",
    "\n",
    "def main_():\n",
    "    \"\"\"main function, set up config.\"\"\"\n",
    "    config = get_config()\n",
    "\n",
    "    # Cuda device\n",
    "    context_setup(config.gpu, config.device, getattr(md.context, config.mode))\n",
    "\n",
    "    # Output directory\n",
    "    base_dir = config.base_dir\n",
    "    if not os.path.exists(base_dir):\n",
    "        os.makedirs(base_dir)\n",
    "\n",
    "    # Experiment name\n",
    "    exp_name = config.dataset_type + \"_\" + config.name\n",
    "    # get the experiment number\n",
    "    exp_num = max([int(fn.split(\"_\")[-1]) for fn in os.listdir(base_dir) if fn.find(exp_name) >= 0] + [0])\n",
    "    if config.no_reload:\n",
    "        exp_num += 1\n",
    "\n",
    "    # Output directory\n",
    "    out_dir = os.path.join(base_dir, exp_name + \"_\" + str(exp_num))\n",
    "\n",
    "    # Start training pipeline\n",
    "    train_pipeline(config, out_dir)\n",
    "\n",
    "main_()\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
